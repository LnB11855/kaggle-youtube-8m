{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'IPython.utils.text.SList'>\n",
      "kaggleyoutube-8m-mlengine\r\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = ! gcloud config list project --format \"value(core.project)\"\n",
    "print type(PROJECT_ID)\n",
    "BUCKET_NAME = PROJECT_ID[2] + \"-mlengine\"\n",
    "! echo $BUCKET_NAME\n",
    "\n",
    "REGION = 'europe-west1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Downloads 55MB of data.\n",
    "! gsutil cp gs://us.data.yt8m.org/1/video_level/train/traina[0-9].tfrecord \\\n",
    "    ./tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the new bucket:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://kaggleyoutube-8m-mlengine/...\n",
      "ServiceException: 409 Bucket kaggleyoutube-8m-mlengine already exists.\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l $REGION gs://$BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://data/traina0.tfrecord [Content-Type=application/octet-stream]...\n",
      "Copying file://data/traina1.tfrecord [Content-Type=application/octet-stream]... \n",
      "Copying file://data/traina2.tfrecord [Content-Type=application/octet-stream]... \n",
      "Copying file://data/traina3.tfrecord [Content-Type=application/octet-stream]... \n",
      "\\ [4 files][ 21.9 MiB/ 21.9 MiB]    2.6 MiB/s                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m -o ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://data/traina4.tfrecord [Content-Type=application/octet-stream]...\n",
      "Copying file://data/traina5.tfrecord [Content-Type=application/octet-stream]... \n",
      "Copying file://data/traina6.tfrecord [Content-Type=application/octet-stream]... \n",
      "Copying file://data/traina7.tfrecord [Content-Type=application/octet-stream]... \n",
      "Copying file://data/traina8.tfrecord [Content-Type=application/octet-stream]... \n",
      "Copying file://data/traina9.tfrecord [Content-Type=application/octet-stream]... \n",
      "| [10 files][ 54.7 MiB/ 54.7 MiB]    1.7 MiB/s                                  \n",
      "Operation completed over 10 objects/54.7 MiB.                                    \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp -r data gs://$BUCKET_NAME/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yt8m_train_20170310_021542\n",
      "'gs://kaggleyoutube-8m-mlengine/data/train*.tfrecord'\n"
     ]
    }
   ],
   "source": [
    "d = datetime.datetime.today()\n",
    "d = d.strftime('%Y%m%d_%H%M%S')\n",
    "JOB_NAME = 'yt8m_train_' + d\n",
    "print JOB_NAME\n",
    "\n",
    "train_data_pattern = '\\'gs://' + BUCKET_NAME + '/data/train*.tfrecord\\''\n",
    "print train_data_pattern"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--config=youtube-8m/cloudml-gpu.yaml \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yt8m_train_20170310_021549\n",
      "DEBUG: Running gcloud.ml-engine.jobs.submit.training with Namespace(_deepest_parser=ArgumentParser(prog='gcloud.ml-engine.jobs.submit.training', usage=None, description='Submits a Cloud Machine Learning training job.', version=None, formatter_class=<class 'argparse.HelpFormatter'>, conflict_handler='error', add_help=False), _specified_args={'staging_bucket': '--staging-bucket', 'verbosity': '--verbosity', 'package_path': '--package-path', 'module_name': '--module-name', 'region': '--region', 'config': '--config', 'job': 'JOB'}, account=None, async=False, authority_selector=None, authorization_token_file=None, calliope_command=<googlecloudsdk.calliope.backend.Command object at 0x10e3e81d0>, command_path=['gcloud', 'ml-engine', 'jobs', 'submit', 'training'], config='youtube-8m/cloudml-gpu.yaml', configuration=None, credential_file_override=None, document=None, flatten=None, format=None, h=None, help=None, http_timeout=None, job='yt8m_train_20170310_021549', job_dir=None, log_http=None, module_name='youtube-8m.train', package_path='youtube-8m', packages=[], project=None, quiet=None, region='europe-west1', runtime_version=None, scale_tier=None, staging_bucket=<googlecloudsdk.api_lib.storage.storage_util.BucketReference object at 0x10e5d6710>, trace_email=None, trace_log=None, trace_token=None, user_args=['--train_data_pattern=gs://kaggleyoutube-8m-mlengine/data/train*.tfrecord', '--model=LogisticModel', '--train_dir=kaggleyoutube-8m-mlengine/yt8m_train_video_level_logistic_model'], user_output_enabled=None, verbosity='debug', version=None).\n",
      "DEBUG: Looking for setup.py file at [/Users/fuyangliu/Workspace/kaggleyoutube-8m/setup.py]\n",
      "INFO: Generating temporary setup.py file:\n",
      "from setuptools import setup\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    setup(name='youtube-8m', packages=['youtube-8m'])\n",
      "\n",
      "DEBUG: Executing command: ['/Users/fuyangliu/Workspace/kaggleyoutube-8m/venv/bin/python2', '/Users/fuyangliu/Workspace/kaggleyoutube-8m/setup.py', 'egg_info', '--egg-base', '/var/folders/h1/r703crvs2r91qx_j0lq3y5vr0000gn/T/tmpKLwDCn', 'build', '--build-base', '/var/folders/h1/r703crvs2r91qx_j0lq3y5vr0000gn/T/tmpKLwDCn', '--build-temp', '/var/folders/h1/r703crvs2r91qx_j0lq3y5vr0000gn/T/tmpKLwDCn', 'sdist', '--dist-dir', '/var/folders/h1/r703crvs2r91qx_j0lq3y5vr0000gn/T/tmpSWpTmn/output']\n",
      "DEBUG: Python packaging resulted in [/var/folders/h1/r703crvs2r91qx_j0lq3y5vr0000gn/T/tmpSWpTmn/output/youtube-8m-0.0.0.tar.gz]\n",
      "DEBUG: Couldn't remove file [/Users/fuyangliu/Workspace/kaggleyoutube-8m/setup.pyc] (it may never have been created).\n",
      "INFO: Uploading [/var/folders/h1/r703crvs2r91qx_j0lq3y5vr0000gn/T/tmpSWpTmn/output/youtube-8m-0.0.0.tar.gz] to [yt8m_train_20170310_021549/86ce8d2e2d4ea68979c322e2710c04870e860855/youtube-8m-0.0.0.tar.gz]\n",
      "DEBUG: Using [u'gs://kaggleyoutube-8m-mlengine/yt8m_train_20170310_021549/86ce8d2e2d4ea68979c322e2710c04870e860855/youtube-8m-0.0.0.tar.gz'] as trainer uris\n",
      "Job [yt8m_train_20170310_021549] submitted successfully.\n",
      "INFO\t2017-03-10 02:15:51 +0100\tunknown_task\t\tValidating job requirements...\n",
      "INFO\t2017-03-10 02:15:52 +0100\tunknown_task\t\tJob creation request has been successfully validated.\n",
      "INFO\t2017-03-10 02:15:52 +0100\tunknown_task\t\tJob yt8m_train_20170310_021549 is queued.\n",
      "INFO\t2017-03-10 02:15:57 +0100\tunknown_task\t\tWaiting for job to be provisioned.\n",
      "INFO\t2017-03-10 02:19:28 +0100\tunknown_task\t\tWaiting for TensorFlow to start.\n",
      "INFO\t2017-03-10 02:21:44 +0100\tmaster-replica-0\t\tRunning task with arguments: --cluster={\"master\": [\"master-62e2fb39fc-0:2222\"]} --task={\"type\": \"master\", \"index\": 0} --job={\n",
      "INFO\t2017-03-10 02:21:44 +0100\tmaster-replica-0\t\t  \"scale_tier\": \"CUSTOM\",\n",
      "INFO\t2017-03-10 02:21:44 +0100\tmaster-replica-0\t\t  \"master_type\": \"standard_gpu\",\n",
      "INFO\t2017-03-10 02:21:44 +0100\tmaster-replica-0\t\t  \"package_uris\": [\"gs://kaggleyoutube-8m-mlengine/yt8m_train_20170310_021549/86ce8d2e2d4ea68979c322e2710c04870e860855/youtube-8m-0.0.0.tar.gz\"],\n",
      "INFO\t2017-03-10 02:21:44 +0100\tmaster-replica-0\t\t  \"python_module\": \"youtube-8m.train\",\n",
      "INFO\t2017-03-10 02:21:44 +0100\tmaster-replica-0\t\t  \"args\": [\"--train_data_pattern=gs://kaggleyoutube-8m-mlengine/data/train*.tfrecord\", \"--model=LogisticModel\", \"--train_dir=kaggleyoutube-8m-mlengine/yt8m_train_video_level_logistic_model\"],\n",
      "INFO\t2017-03-10 02:21:44 +0100\tmaster-replica-0\t\t  \"region\": \"europe-west1\",\n",
      "INFO\t2017-03-10 02:21:44 +0100\tmaster-replica-0\t\t  \"runtime_version\": \"1.0\"\n",
      "INFO\t2017-03-10 02:21:44 +0100\tmaster-replica-0\t\t}\n",
      "INFO\t2017-03-10 02:22:04 +0100\tmaster-replica-0\t\tRetrying credential refresh after error Unable to find the server at metadata.google.internal.\n",
      "INFO\t2017-03-10 02:22:25 +0100\tmaster-replica-0\t\tRunning module youtube-8m.train.\n",
      "INFO\t2017-03-10 02:22:25 +0100\tmaster-replica-0\t\tDownloading the package: gs://kaggleyoutube-8m-mlengine/yt8m_train_20170310_021549/86ce8d2e2d4ea68979c322e2710c04870e860855/youtube-8m-0.0.0.tar.gz\n",
      "INFO\t2017-03-10 02:22:25 +0100\tmaster-replica-0\t\tRunning command: gsutil -q cp gs://kaggleyoutube-8m-mlengine/yt8m_train_20170310_021549/86ce8d2e2d4ea68979c322e2710c04870e860855/youtube-8m-0.0.0.tar.gz youtube-8m-0.0.0.tar.gz\n",
      "INFO\t2017-03-10 02:22:26 +0100\tmaster-replica-0\t\tInstalling the package: gs://kaggleyoutube-8m-mlengine/yt8m_train_20170310_021549/86ce8d2e2d4ea68979c322e2710c04870e860855/youtube-8m-0.0.0.tar.gz\n",
      "INFO\t2017-03-10 02:22:26 +0100\tmaster-replica-0\t\tRunning command: pip install --user --upgrade --force-reinstall youtube-8m-0.0.0.tar.gz\n",
      "INFO\t2017-03-10 02:22:26 +0100\tmaster-replica-0\t\tProcessing ./youtube-8m-0.0.0.tar.gz\n",
      "INFO\t2017-03-10 02:22:26 +0100\tmaster-replica-0\t\tBuilding wheels for collected packages: youtube-8m\n",
      "INFO\t2017-03-10 02:22:26 +0100\tmaster-replica-0\t\t  Running setup.py bdist_wheel for youtube-8m: started\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tcreating '/tmp/tmpI2UZmipip-wheel-/youtube_8m-0.0.0-cp27-none-any.whl' and adding '.' to it\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube-8m/convert_prediction_from_json_to_csv.py'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube-8m/losses.py'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube-8m/frame_level_models.py'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube-8m/models.py'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube-8m/export_model.py'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube-8m/readers.py'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube-8m/model_utils.py'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube-8m/__init__.py'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube-8m/inference.py'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube-8m/utils.py'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube-8m/eval.py'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube_8m-0.0.0.dist-info/metadata.json'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube_8m-0.0.0.dist-info/top_level.txt'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube_8m-0.0.0.dist-info/WHEEL'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tadding 'youtube_8m-0.0.0.dist-info/RECORD'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\t  Running setup.py bdist_wheel for youtube-8m: finished with status 'done'\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\t  Stored in directory: /root/.cache/pip/wheels/d8/65/64/bd509724942d531083372fbe3d32e7917976d6ad759d0db48d\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tSuccessfully built youtube-8m\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tInstalling collected packages: youtube-8m\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tSuccessfully installed youtube-8m-0.0.0\n",
      "INFO\t2017-03-10 02:22:27 +0100\tmaster-replica-0\t\tRunning command: python -m youtube-8m.train --train_data_pattern=gs://kaggleyoutube-8m-mlengine/data/train*.tfrecord --model=LogisticModel --train_dir=kaggleyoutube-8m-mlengine/yt8m_train_video_level_logistic_model\n",
      "INFO\t2017-03-10 02:22:29 +0100\tmaster-replica-0\t\tsuccessfully opened CUDA library libcublas.so.8.0 locally\n",
      "INFO\t2017-03-10 02:22:29 +0100\tmaster-replica-0\t\tsuccessfully opened CUDA library libcudnn.so.5 locally\n",
      "INFO\t2017-03-10 02:22:30 +0100\tmaster-replica-0\t\tsuccessfully opened CUDA library libcufft.so.8.0 locally\n",
      "INFO\t2017-03-10 02:22:30 +0100\tmaster-replica-0\t\tsuccessfully opened CUDA library libcuda.so.1 locally\n",
      "INFO\t2017-03-10 02:22:30 +0100\tmaster-replica-0\t\tsuccessfully opened CUDA library libcurand.so.8.0 locally\n",
      "INFO\t2017-03-10 02:22:32 +0100\tmaster-replica-0\t\t/job:master/task:0: Tensorflow version: 1.0.1.\n",
      "INFO\t2017-03-10 02:22:32 +0100\tmaster-replica-0\t\t/job:master/task:0: Starting trainer within cluster {u'master': [u'master-62e2fb39fc-0:2222']}.\n",
      "WARNING\t2017-03-10 02:22:32 +0100\tmaster-replica-0\t\tThe TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "WARNING\t2017-03-10 02:22:32 +0100\tmaster-replica-0\t\tThe TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "INFO\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tsuccessful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "INFO\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tFound device 0 with properties: \n",
      "ERROR\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tname: Tesla K80\n",
      "ERROR\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tmajor: 3 minor: 7 memoryClockRate (GHz) 0.8235\n",
      "ERROR\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tpciBusID 0000:00:04.0\n",
      "ERROR\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tTotal memory: 11.20GiB\n",
      "ERROR\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tFree memory: 11.13GiB\n",
      "INFO\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tDMA: 0 \n",
      "INFO\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\t0:   Y \n",
      "INFO\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tCreating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)\n",
      "INFO\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tInitialize GrpcChannelCache for job master -> {0 -> localhost:2222}\n",
      "INFO\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tStarted server with target: grpc://localhost:2222\n",
      "INFO\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\t/job:master/task:0: No checkpoint file found. Building a new model.\n",
      "INFO\t2017-03-10 02:22:34 +0100\tmaster-replica-0\t\tUsing batch size of 1024 for training.\n",
      "INFO\t2017-03-10 02:22:35 +0100\tmaster-replica-0\t\tNumber of training files: 10.\n",
      "INFO\t2017-03-10 02:22:35 +0100\tmaster-replica-0\t\t/job:master/task:0: Starting managed session.\n",
      "INFO\t2017-03-10 02:22:35 +0100\tmaster-replica-0\t\tStart master session e8bffe8d022dbcd5 with config: \n",
      "INFO\t2017-03-10 02:22:36 +0100\tmaster-replica-0\t\t/job:master/task:0: Entering training loop.\n",
      "INFO\t2017-03-10 02:22:36 +0100\tmaster-replica-0\t\tglobal_step/sec: 0\n",
      "INFO\t2017-03-10 02:22:36 +0100\tmaster-replica-0\t\tkaggleyoutube-8m-mlengine/yt8m_train_video_level_logistic_model/model.ckpt-0 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO\t2017-03-10 02:22:37 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 1| Hit@1: 0.00 PERR: 0.00 GAP: 0.00 Loss: 3268.99\n",
      "INFO\t2017-03-10 02:22:37 +0100\tmaster-replica-0\t\tkaggleyoutube-8m-mlengine/yt8m_train_video_level_logistic_model/model.ckpt-1 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "INFO\t2017-03-10 02:22:37 +0100\tmaster-replica-0\t\t/job:master/task:0: Exporting the model at step 1 to kaggleyoutube-8m-mlengine/yt8m_train_video_level_logistic_model/export/step_1.\n",
      "INFO\t2017-03-10 02:22:37 +0100\tmaster-replica-0\t\tCreating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0)\n",
      "INFO\t2017-03-10 02:22:37 +0100\tmaster-replica-0\t\tNo assets to save.\n",
      "INFO\t2017-03-10 02:22:37 +0100\tmaster-replica-0\t\tNo assets to write.\n",
      "INFO\t2017-03-10 02:22:37 +0100\tmaster-replica-0\t\tSavedModel written to: kaggleyoutube-8m-mlengine/yt8m_train_video_level_logistic_model/export/step_1/saved_model.pb\n",
      "INFO\t2017-03-10 02:22:37 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 2| Hit@1: 0.02 PERR: 0.01 GAP: 0.00 Loss: 3243.73\n",
      "INFO\t2017-03-10 02:22:38 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 3| Hit@1: 0.16 PERR: 0.09 GAP: 0.01 Loss: 3213.87\n",
      "INFO\t2017-03-10 02:22:38 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 4| Hit@1: 0.27 PERR: 0.15 GAP: 0.03 Loss: 3196.45\n",
      "INFO\t2017-03-10 02:22:39 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 5| Hit@1: 0.34 PERR: 0.21 GAP: 0.07 Loss: 3169.88\n",
      "INFO\t2017-03-10 02:22:39 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 6| Hit@1: 0.43 PERR: 0.27 GAP: 0.14 Loss: 3141.21\n",
      "INFO\t2017-03-10 02:22:39 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 7| Hit@1: 0.47 PERR: 0.30 GAP: 0.16 Loss: 3116.49\n",
      "INFO\t2017-03-10 02:22:40 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 8| Hit@1: 0.50 PERR: 0.34 GAP: 0.21 Loss: 3087.48\n",
      "INFO\t2017-03-10 02:22:40 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 9| Hit@1: 0.53 PERR: 0.36 GAP: 0.22 Loss: 3063.46\n",
      "INFO\t2017-03-10 02:22:40 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 10| Hit@1: 0.58 PERR: 0.40 GAP: 0.28 Loss: 3031.81\n",
      "INFO\t2017-03-10 02:22:41 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 11| Hit@1: 0.58 PERR: 0.41 GAP: 0.28 Loss: 3001.65\n",
      "INFO\t2017-03-10 02:22:41 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 12| Hit@1: 0.62 PERR: 0.44 GAP: 0.32 Loss: 2979.38\n",
      "INFO\t2017-03-10 02:22:42 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 13| Hit@1: 0.64 PERR: 0.45 GAP: 0.33 Loss: 2958.41\n",
      "INFO\t2017-03-10 02:22:42 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 14| Hit@1: 0.61 PERR: 0.43 GAP: 0.33 Loss: 2939.33\n",
      "INFO\t2017-03-10 02:22:42 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 15| Hit@1: 0.65 PERR: 0.47 GAP: 0.32 Loss: 2907.61\n",
      "INFO\t2017-03-10 02:22:43 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 16| Hit@1: 0.65 PERR: 0.47 GAP: 0.34 Loss: 2880.76\n",
      "INFO\t2017-03-10 02:22:43 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 17| Hit@1: 0.65 PERR: 0.48 GAP: 0.36 Loss: 2867.53\n",
      "INFO\t2017-03-10 02:22:44 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 18| Hit@1: 0.66 PERR: 0.49 GAP: 0.38 Loss: 2824.15\n",
      "INFO\t2017-03-10 02:22:44 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 19| Hit@1: 0.67 PERR: 0.51 GAP: 0.42 Loss: 2814.59\n",
      "INFO\t2017-03-10 02:22:44 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 20| Hit@1: 0.66 PERR: 0.50 GAP: 0.41 Loss: 2790.24\n",
      "INFO\t2017-03-10 02:22:45 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 21| Hit@1: 0.69 PERR: 0.51 GAP: 0.43 Loss: 2764.12\n",
      "INFO\t2017-03-10 02:22:45 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 22| Hit@1: 0.67 PERR: 0.49 GAP: 0.42 Loss: 2738.84\n",
      "INFO\t2017-03-10 02:22:45 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 23| Hit@1: 0.65 PERR: 0.49 GAP: 0.41 Loss: 2718.99\n",
      "INFO\t2017-03-10 02:22:46 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 24| Hit@1: 0.66 PERR: 0.51 GAP: 0.43 Loss: 2688.91\n",
      "INFO\t2017-03-10 02:22:46 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 25| Hit@1: 0.69 PERR: 0.52 GAP: 0.45 Loss: 2666.69\n",
      "INFO\t2017-03-10 02:22:47 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 26| Hit@1: 0.69 PERR: 0.52 GAP: 0.46 Loss: 2634.23\n",
      "INFO\t2017-03-10 02:22:47 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 27| Hit@1: 0.68 PERR: 0.52 GAP: 0.45 Loss: 2620.4\n",
      "INFO\t2017-03-10 02:22:47 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 28| Hit@1: 0.69 PERR: 0.51 GAP: 0.46 Loss: 2592.25\n",
      "INFO\t2017-03-10 02:22:48 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 29| Hit@1: 0.70 PERR: 0.54 GAP: 0.46 Loss: 2580.59\n",
      "INFO\t2017-03-10 02:22:48 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 30| Hit@1: 0.69 PERR: 0.50 GAP: 0.44 Loss: 2552.49\n",
      "INFO\t2017-03-10 02:22:48 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 31| Hit@1: 0.70 PERR: 0.53 GAP: 0.47 Loss: 2543.27\n",
      "INFO\t2017-03-10 02:22:49 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 32| Hit@1: 0.69 PERR: 0.52 GAP: 0.45 Loss: 2508.86\n",
      "INFO\t2017-03-10 02:22:49 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 33| Hit@1: 0.67 PERR: 0.50 GAP: 0.47 Loss: 2492.84\n",
      "INFO\t2017-03-10 02:22:51 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 37| Hit@1: 0.69 PERR: 0.54 GAP: 0.50 Loss: 2411.1\n",
      "INFO\t2017-03-10 02:22:51 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 38| Hit@1: 0.70 PERR: 0.55 GAP: 0.49 Loss: 2376.93\n",
      "INFO\t2017-03-10 02:22:51 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 39| Hit@1: 0.69 PERR: 0.52 GAP: 0.48 Loss: 2370.74\n",
      "INFO\t2017-03-10 02:22:52 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 40| Hit@1: 0.68 PERR: 0.53 GAP: 0.50 Loss: 2354.13\n",
      "INFO\t2017-03-10 02:22:52 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 41| Hit@1: 0.71 PERR: 0.53 GAP: 0.49 Loss: 2309.61\n",
      "INFO\t2017-03-10 02:22:52 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 42| Hit@1: 0.72 PERR: 0.53 GAP: 0.49 Loss: 2298.79\n",
      "INFO\t2017-03-10 02:22:53 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 43| Hit@1: 0.69 PERR: 0.53 GAP: 0.51 Loss: 2272.84\n",
      "INFO\t2017-03-10 02:22:53 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 44| Hit@1: 0.70 PERR: 0.54 GAP: 0.49 Loss: 2269.28\n",
      "INFO\t2017-03-10 02:22:54 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 45| Hit@1: 0.70 PERR: 0.53 GAP: 0.50 Loss: 2244.8\n",
      "INFO\t2017-03-10 02:22:54 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 46| Hit@1: 0.69 PERR: 0.53 GAP: 0.50 Loss: 2232.35\n",
      "INFO\t2017-03-10 02:22:54 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 47| Hit@1: 0.69 PERR: 0.54 GAP: 0.51 Loss: 2212.26\n",
      "INFO\t2017-03-10 02:22:55 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 48| Hit@1: 0.70 PERR: 0.53 GAP: 0.49 Loss: 2179.38\n",
      "INFO\t2017-03-10 02:22:55 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 49| Hit@1: 0.67 PERR: 0.52 GAP: 0.50 Loss: 2169.83\n",
      "WARNING\t2017-03-10 02:22:55 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:55 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_3 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_3, train_input/input_producer, train_input/ReaderReadUpToV2_3/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:55 +0100\tmaster-replica-0\t\t\t [[Node: train_input/SparseToIndicator_3/Shape_G56 = _HostRecv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_15_train_input/SparseToIndicator_3/Shape\", tensor_type=DT_INT32, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:55 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:55 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_3 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_3, train_input/input_producer, train_input/ReaderReadUpToV2_3/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:55 +0100\tmaster-replica-0\t\t\t [[Node: train_input/SparseToIndicator_3/Shape_G56 = _HostRecv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_15_train_input/SparseToIndicator_3/Shape\", tensor_type=DT_INT32, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:55 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:55 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_3 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_3, train_input/input_producer, train_input/ReaderReadUpToV2_3/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:55 +0100\tmaster-replica-0\t\t\t [[Node: train_input/SparseToIndicator_3/Shape_G56 = _HostRecv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_15_train_input/SparseToIndicator_3/Shape\", tensor_type=DT_INT32, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "INFO\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 50| Hit@1: 0.69 PERR: 0.51 GAP: 0.48 Loss: 2167.76\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_4 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_4, train_input/input_producer, train_input/ReaderReadUpToV2_4/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/Shape_4_G207 = _HostRecv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_60_train_input/Shape_4\", tensor_type=DT_INT32, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_4 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_4, train_input/input_producer, train_input/ReaderReadUpToV2_4/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/Shape_4_G207 = _HostRecv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_60_train_input/Shape_4\", tensor_type=DT_INT32, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_1 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_1, train_input/input_producer, train_input/ReaderReadUpToV2_1/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/shuffle_batch_join/cond_1/random_shuffle_queue_EnqueueMany_G253 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_97_train_input/shuffle_batch_join/cond_1/random_shuffle_queue_EnqueueMany\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_4 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_4, train_input/input_producer, train_input/ReaderReadUpToV2_4/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/Shape_4_G207 = _HostRecv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_60_train_input/Shape_4\", tensor_type=DT_INT32, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_1 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_1, train_input/input_producer, train_input/ReaderReadUpToV2_1/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/shuffle_batch_join/cond_1/random_shuffle_queue_EnqueueMany_G253 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_97_train_input/shuffle_batch_join/cond_1/random_shuffle_queue_EnqueueMany\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_7 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_7, train_input/input_producer, train_input/ReaderReadUpToV2_7/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ParseExample_7/ParseExample_G283 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_14_train_input/ParseExample_7/ParseExample\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_1 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_1, train_input/input_producer, train_input/ReaderReadUpToV2_1/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/shuffle_batch_join/cond_1/random_shuffle_queue_EnqueueMany_G253 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_97_train_input/shuffle_batch_join/cond_1/random_shuffle_queue_EnqueueMany\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_7 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_7, train_input/input_producer, train_input/ReaderReadUpToV2_7/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ParseExample_7/ParseExample_G283 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_14_train_input/ParseExample_7/ParseExample\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_7 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_7, train_input/input_producer, train_input/ReaderReadUpToV2_7/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ParseExample_7/ParseExample_G283 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_14_train_input/ParseExample_7/ParseExample\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "INFO\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 51| Hit@1: 0.71 PERR: 0.54 GAP: 0.50 Loss: 2135.1\n",
      "INFO\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 52| Hit@1: 0.71 PERR: 0.54 GAP: 0.51 Loss: 2109.91\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_5 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_5, train_input/input_producer, train_input/ReaderReadUpToV2_5/num_records)]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_5 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_5, train_input/input_producer, train_input/ReaderReadUpToV2_5/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ParseExample_5/ParseExample_G71 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_14_train_input/ParseExample_5/ParseExample\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_2 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_2, train_input/input_producer, train_input/ReaderReadUpToV2_2/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/SparseToIndicator_2/Shape_1_G95 = _HostRecv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_23_train_input/SparseToIndicator_2/Shape_1\", tensor_type=DT_INT32, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_2 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_2, train_input/input_producer, train_input/ReaderReadUpToV2_2/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/SparseToIndicator_2/Shape_1_G95 = _HostRecv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_23_train_input/SparseToIndicator_2/Shape_1\", tensor_type=DT_INT32, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_2 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_2, train_input/input_producer, train_input/ReaderReadUpToV2_2/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:56 +0100\tmaster-replica-0\t\t\t [[Node: train_input/SparseToIndicator_2/Shape_1_G95 = _HostRecv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_23_train_input/SparseToIndicator_2/Shape_1\", tensor_type=DT_INT32, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "INFO\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 53| Hit@1: 0.70 PERR: 0.54 GAP: 0.52 Loss: 2099.1\n",
      "WARNING\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_6 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_6, train_input/input_producer, train_input/ReaderReadUpToV2_6/num_records)]]\n",
      "WARNING\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2_6 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2_6, train_input/input_producer, train_input/ReaderReadUpToV2_6/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ParseExample_6/ParseExample_G51 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_14_train_input/ParseExample_6/ParseExample\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2, train_input/input_producer, train_input/ReaderReadUpToV2/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ParseExample/ParseExample_G297 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_14_train_input/ParseExample/ParseExample\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2, train_input/input_producer, train_input/ReaderReadUpToV2/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ParseExample/ParseExample_G297 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_14_train_input/ParseExample/ParseExample\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "WARNING\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\tOut of range: FIFOQueue '_0_train_input/input_producer' is closed and has insufficient elements (requested 1, current size 0)\n",
      "ERROR\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ReaderReadUpToV2 = ReaderReadUpToV2[_device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/TFRecordReaderV2, train_input/input_producer, train_input/ReaderReadUpToV2/num_records)]]\n",
      "ERROR\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t\t [[Node: train_input/ParseExample/ParseExample_G297 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_14_train_input/ParseExample/ParseExample\", tensor_type=DT_FLOAT, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "INFO\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 54| Hit@1: 0.70 PERR: 0.54 GAP: 0.51 Loss: 2088.09\n",
      "INFO\t2017-03-10 02:22:57 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 55| Hit@1: 0.70 PERR: 0.55 GAP: 0.53 Loss: 2048.39\n",
      "INFO\t2017-03-10 02:22:58 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 56| Hit@1: 0.71 PERR: 0.53 GAP: 0.51 Loss: 2049.79\n",
      "INFO\t2017-03-10 02:22:58 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 57| Hit@1: 0.70 PERR: 0.54 GAP: 0.52 Loss: 2018.78\n",
      "INFO\t2017-03-10 02:22:59 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 58| Hit@1: 0.72 PERR: 0.53 GAP: 0.51 Loss: 2031.52\n",
      "INFO\t2017-03-10 02:22:59 +0100\tmaster-replica-0\t\t/job:master/task:0: training step 59| Hit@1: 0.70 PERR: 0.55 GAP: 0.54 Loss: 1973.2\n",
      "WARNING\t2017-03-10 02:22:59 +0100\tmaster-replica-0\t\tOut of range: RandomShuffleQueue '_2_train_input/shuffle_batch_join/random_shuffle_queue' is closed and has insufficient elements (requested 1024, current size 0)\n",
      "INFO\t2017-03-10 02:22:59 +0100\tmaster-replica-0\t\t/job:master/task:0: Done training -- epoch limit reached.\n",
      "ERROR\t2017-03-10 02:22:59 +0100\tmaster-replica-0\t\t\t [[Node: train_input/shuffle_batch_join = QueueDequeueUpToV2[component_types=[DT_STRING, DT_FLOAT, DT_BOOL, DT_FLOAT], timeout_ms=-1, _device=\"/job:master/replica:0/task:0/cpu:0\"](train_input/shuffle_batch_join/random_shuffle_queue, train_input/shuffle_batch_join/n)]]\n",
      "ERROR\t2017-03-10 02:22:59 +0100\tmaster-replica-0\t\t\t [[Node: train_input/shuffle_batch_join_G406 = _Recv[client_terminated=false, recv_device=\"/job:master/replica:0/task:0/gpu:0\", send_device=\"/job:master/replica:0/task:0/cpu:0\", send_device_incarnation=7596838075895200040, tensor_name=\"edge_21_train_input/shuffle_batch_join\", tensor_type=DT_BOOL, _device=\"/job:master/replica:0/task:0/gpu:0\"]()]]\n",
      "INFO\t2017-03-10 02:22:59 +0100\tmaster-replica-0\t\t/job:master/task:0: Exited training loop.\n",
      "INFO\t2017-03-10 02:22:59 +0100\tmaster-replica-0\t\tModule completed; cleaning up.\n",
      "INFO\t2017-03-10 02:22:59 +0100\tmaster-replica-0\t\tClean up finished.\n",
      "INFO\t2017-03-10 02:22:59 +0100\tmaster-replica-0\t\tTask completed successfully.\n",
      "INFO: Display format \"yaml(jobId,state,startTime.date(tz=LOCAL),endTime.date(tz=LOCAL))\".\n",
      "endTime: '2017-03-10T02:23:33'\n",
      "jobId: yt8m_train_20170310_021549\n",
      "startTime: '2017-03-10T02:22:17'\n",
      "state: SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "d = datetime.datetime.today()\n",
    "d = d.strftime('%Y%m%d_%H%M%S')\n",
    "JOB_NAME = 'yt8m_train_' + d\n",
    "print JOB_NAME\n",
    "\n",
    "! gcloud --verbosity=debug ml-engine jobs \\\n",
    "    submit training $JOB_NAME \\\n",
    "    --package-path=youtube-8m --module-name=youtube-8m.train \\\n",
    "    --staging-bucket=gs://$BUCKET_NAME --region=$REGION \\\n",
    "    --config=youtube-8m/cloudml-gpu.yaml \\\n",
    "    -- --train_data_pattern=$train_data_pattern \\\n",
    "    --model=LogisticModel \\\n",
    "    --train_dir=$BUCKET_NAME/yt8m_train_video_level_logistic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: export: No such file or directory\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Your active configuration is: [default]', '', 'kaggleyoutube-8m']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
